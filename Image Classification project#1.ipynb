{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUf7lS-PL0Bu",
        "outputId": "36ffb336-c131-4374-a546-48a92b47f3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtUirL5kEvZs"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00EIfdPRMAvf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import *\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import InceptionV3, EfficientNetB0, ResNet50, VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau,ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "#import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c0Xz4chE5HY"
      },
      "source": [
        "# **Read Data and Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhLNF6qqN0zf"
      },
      "outputs": [],
      "source": [
        "def read_and_resize_images(folder_path, label, img_size):\n",
        "    images = []\n",
        "    internal_labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)\n",
        "                if img.shape[:2] == img_size:\n",
        "                    images.append(img)\n",
        "                    internal_labels.append(label)\n",
        "\n",
        "    num_images = len(images)\n",
        "    print(f\"Loaded {num_images} images for class {label} from folder {folder_path}\")\n",
        "    return images, internal_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-fOmxjE-qm"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9ELS4M8N4ou"
      },
      "outputs": [],
      "source": [
        "def load_dataset(root_folder,img_size):\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    class_folders = sorted(os.listdir(root_folder))\n",
        "\n",
        "    for label, class_folder in enumerate(class_folders):\n",
        "        class_path = os.path.join(root_folder, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            images, labels = read_and_resize_images(class_path, label,img_size)\n",
        "            all_images.extend(images)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    all_labels = to_categorical(all_labels, num_classes=len(class_folders))\n",
        "\n",
        "    return np.array(all_images), np.array(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf660sjdFE03"
      },
      "source": [
        "# **Plot image from each class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9zVr11NN6u3"
      },
      "outputs": [],
      "source": [
        "def plot_images(images, labels, class_folders):\n",
        "    num_classes = len(class_folders)\n",
        "    fig, axes = plt.subplots(1, num_classes, figsize=(15, 3))\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        class_images = images[labels[:, i] == 1]\n",
        "        axes[i].imshow(class_images[0][:, :, ::-1])\n",
        "        axes[i].set_title(f\" {class_folders[i]}\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvCgMyLCFI95"
      },
      "source": [
        "# **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIywmslJOHul"
      },
      "outputs": [],
      "source": [
        "def augment_images(images):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    augmented_images = []\n",
        "    for img in images:\n",
        "        img = img.reshape((1,) + img.shape)\n",
        "        for batch in datagen.flow(img, batch_size=1):\n",
        "            augmented_images.append(batch[0])\n",
        "            break\n",
        "\n",
        "    return np.array(augmented_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lez220tBFPyo"
      },
      "source": [
        "# **Creat and train model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9AfVZiSFUuj"
      },
      "source": [
        "# Inceptionv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E23s_78xOpQ8"
      },
      "outputs": [],
      "source": [
        "def create_inceptionv3_model(shape):\n",
        "    InceptionV3_model = InceptionV3(input_shape=shape, weights='imagenet', include_top=False)\n",
        "\n",
        "    InceptionV3_model = InceptionV3(input_shape=(150,150,3),weights='imagenet', include_top=False)\n",
        "    for layer in InceptionV3_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    InceptionV3_last_output = InceptionV3_model.output\n",
        "    InceptionV3_maxpooled_output = Flatten()(InceptionV3_last_output)\n",
        "    InceptionV3_x = Dense(1024, activation='relu')(InceptionV3_maxpooled_output)\n",
        "    InceptionV3_x = Dropout(0.5)(InceptionV3_x)\n",
        "    InceptionV3_x = Dense(6, activation='softmax')(InceptionV3_x)\n",
        "    InceptionV3_x_final_model = Model(inputs=InceptionV3_model.input,outputs=InceptionV3_x)\n",
        "    InceptionV3_x_final_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    return InceptionV3_x_final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wTrqA_nOwb3"
      },
      "outputs": [],
      "source": [
        "def train_inceptionv3_model(model, train_generator, validation_generator, number_of_epochs=100):\n",
        "    inception_filepath = 'inceptionv3_-saved-model-{epoch:02d}-val_accuracy-{val_accuracy:.2f}.hdf5'\n",
        "    inception_checkpoint = tf.keras.callbacks.ModelCheckpoint(inception_filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    inception_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
        "\n",
        "    history = model.fit(train_generator, epochs=number_of_epochs, validation_data=validation_generator,\n",
        "                        callbacks=[inception_checkpoint, inception_early_stopping], verbose=1)\n",
        "    test_loss, test_acc = model.evaluate(validation_generator)\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])  # Change 'acc' to 'accuracy'\n",
        "    plt.plot(history.history['val_accuracy'])  # Change 'val_acc' to 'val_accuracy'\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUHZ9UyIFcz7"
      },
      "source": [
        "# VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwvEsq5sOvCx"
      },
      "outputs": [],
      "source": [
        "def create_VGG16_model(shape):\n",
        "    vgg16_model = VGG16(pooling='avg', weights='imagenet', include_top=False, input_shape=shape)\n",
        "\n",
        "    for layer in vgg16_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    last_output = vgg16_model.layers[-1].output\n",
        "    vgg_x = Flatten()(last_output)\n",
        "    vgg_x = Dense(100, activation='relu')(vgg_x)\n",
        "    vgg_x = Dense(6, activation='softmax')(vgg_x)\n",
        "\n",
        "    vgg16_final_model = Model(vgg16_model.input, vgg_x)\n",
        "    vgg16_final_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "    return vgg16_final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL_y-CvQS_57"
      },
      "outputs": [],
      "source": [
        "def train_VGG16_model(model, train_generator, validation_generator, epochs, checkpoint_filepath, early_stopping_patience):\n",
        "      vgg_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "      vgg_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stopping_patience)\n",
        "      history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator,callbacks=[vgg_checkpoint, vgg_early_stopping], verbose=1)\n",
        "      test_loss, test_acc = model.evaluate(validation_generator)\n",
        "      print(f'Test Loss: {test_loss:.4f}')\n",
        "      print(f'Test Accuracy: {test_acc:.4f}')\n",
        "      plt.figure(figsize=(12, 4))\n",
        "      # Plot training & validation accuracy values\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(history.history['acc'])\n",
        "      plt.plot(history.history['val_acc'])\n",
        "      plt.title('Model accuracy')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.ylabel('Accuracy')\n",
        "      plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "      # Plot training & validation loss values\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(history.history['loss'])\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.title('Model loss')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.ylabel('Loss')\n",
        "      plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWA873jZFgW4"
      },
      "source": [
        "# ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbHAdxAzJziQ"
      },
      "outputs": [],
      "source": [
        "def create_ResNet50_model(shape):\n",
        "  ResNet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=shape, classes=6)\n",
        "\n",
        "  for layers in ResNet50_model.layers:\n",
        "    layers.trainable=False\n",
        "\n",
        "  opt = SGD(lr=0.01,momentum=0.7)\n",
        "  resnet50_x = Flatten()(ResNet50_model.output)\n",
        "  resnet50_x = Dense(256,activation='relu')(resnet50_x)\n",
        "  resnet50_x = Dense(6,activation='softmax')(resnet50_x)\n",
        "  resnet50_x_final_model = Model(inputs=ResNet50_model.input, outputs=resnet50_x)\n",
        "  resnet50_x_final_model.compile(loss = 'categorical_crossentropy', optimizer= opt, metrics=['acc'])\n",
        "  return resnet50_x_final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrNInakEJzk1"
      },
      "outputs": [],
      "source": [
        "def train_ResNet50_model(model, train_generator, validation_generator, epochs=60):\n",
        "    resnet_filepath = 'resnet50' + '-saved-model-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5'\n",
        "    resnet_checkpoint = ModelCheckpoint(resnet_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    resnet_early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=20, min_lr=0.000002)\n",
        "    callback_list = [resnet_checkpoint, resnet_early_stopping, reduce_lr]\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=callback_list, verbose=1)\n",
        "    test_loss, test_acc = model.evaluate(validation_generator)\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfTE_erKFlou"
      },
      "source": [
        "# EfficientNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAtDrU7KXf_w"
      },
      "outputs": [],
      "source": [
        "def create_EfficientNet_model(shape):\n",
        "    EfficientNet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=shape, classes=6)\n",
        "\n",
        "    for layer in EfficientNet_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    opt = SGD(lr=0.01, momentum=0.7)\n",
        "    efficientnet_x = Flatten()(EfficientNet_model.output)\n",
        "    efficientnet_x = Dense(256, activation='relu')(efficientnet_x)\n",
        "    efficientnet_x = Dense(6, activation='softmax')(efficientnet_x)\n",
        "\n",
        "    efficientnet_final_model = Model(inputs=EfficientNet_model.input, outputs=efficientnet_x)\n",
        "    efficientnet_final_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
        "\n",
        "    return efficientnet_final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1FW5CICXi1Z"
      },
      "outputs": [],
      "source": [
        "def train_EfficientNet_model(model, train_generator, validation_generator, epochs=100):\n",
        "    efficientnet_filepath = 'efficientnet' + '-saved-model-{epoch:02d}-val_acc-{val_acc:.2f}.h5'\n",
        "    efficientnet_checkpoint = ModelCheckpoint(efficientnet_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    efficientnet_early_stopping = EarlyStopping(monitor='loss', patience=20)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, min_lr=0.000002)\n",
        "    callback_list = [efficientnet_checkpoint, efficientnet_early_stopping, reduce_lr]\n",
        "\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=callback_list, verbose=1)\n",
        "    test_loss, test_acc = model.evaluate(validation_generator)\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {test_acc:.4f}')\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aASQ5S3ZhFb"
      },
      "source": [
        "# **Main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzxFqZ5fOxMU"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    img_size = (150, 150)\n",
        "    SEED = 42\n",
        "    BATCH_SIZE = 32\n",
        "    BUFFER_SIZE = 1024\n",
        "    shape=(150, 150, 3)\n",
        "    root_folder = \"/content/drive/MyDrive/Jordan Archaeological Sites\"\n",
        "    class_folders = sorted(os.listdir(root_folder))\n",
        "    images, labels = load_dataset(root_folder,img_size)\n",
        "    plot_images(images, labels, class_folders)\n",
        "\n",
        "    augmented_images = augment_images(images)\n",
        "    images = np.concatenate((images, augmented_images), axis=0)\n",
        "    labels = np.concatenate((labels, labels), axis=0)\n",
        "    print(\"Total number of data after augmentation:\", len(images))\n",
        "\n",
        "\n",
        "\n",
        "    indices = np.arange(len(images))\n",
        "    np.random.seed(SEED)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_size = int(0.9 * len(indices))\n",
        "    val_size = int(0.1 * len(indices))\n",
        "\n",
        "    train_indices = indices[:train_size]\n",
        "    val_indices = indices[train_size:(train_size + val_size)]\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(images[train_indices]), tf.convert_to_tensor(labels[train_indices])))\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(images[val_indices]), tf.convert_to_tensor(labels[val_indices])))\n",
        "\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=BUFFER_SIZE, seed=SEED).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    image_path = \"/content/drive/MyDrive/Test Images/الدير.jpg\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (150, 150))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255.0\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(img[0][:, :, ::-1])\n",
        "    plt.title(\"Predicted Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    user_input = input(\"Pleas Select which model you need :\\n 1-InceptionV3\\n2-Efficientnet\\n3-ResNet\\n4-VGGNet\\n \")\n",
        "    print(\"You entered:\", user_input)\n",
        "    if(user_input.lower()=='inceptionv3'):\n",
        "          inception_model = create_inceptionv3_model(shape)\n",
        "          history = train_inceptionv3_model(inception_model, train_dataset, val_dataset)\n",
        "          predictions = inception_model.predict(img)\n",
        "\n",
        "          # Display predicted probabilities for each class\n",
        "          for i, class_name in enumerate(class_folders):\n",
        "            class_probability = predictions[0, i]\n",
        "            print(f\"{class_name}: {class_probability:.4f}\")\n",
        "    elif(user_input.lower()=='vggnet'):\n",
        "         vgg16_filepath = 'vgg_16_' + '-saved-model-{epoch:02d}-acc-{val_acc:.2f}.hdf5'\n",
        "         vgg_16_model = create_VGG16_model(shape)\n",
        "         # Assuming you have train_generator and validation_generator defined somewhere\n",
        "         # train_vgg16_model function handles the training and checkpoints\n",
        "         vgg16_history = train_VGG16_model(model=vgg_16_model,train_generator=train_dataset,validation_generator=val_dataset,\n",
        "                                           epochs=100,checkpoint_filepath=vgg16_filepath,early_stopping_patience=20)\n",
        "         predictions = vgg_16_model.predict(img)\n",
        "         # Display predicted probabilities for each class\n",
        "         for i, class_name in enumerate(class_folders):\n",
        "            class_probability = predictions[0, i]\n",
        "            print(f\"{class_name}: {class_probability:.4f}\")\n",
        "    elif(user_input.lower()=='resnet'):\n",
        "         resnet50_model = create_ResNet50_model(shape)\n",
        "         history = train_ResNet50_model(resnet50_model, train_dataset, val_dataset)\n",
        "         predictions = resnet50_model.predict(img)\n",
        "         # Display predicted probabilities for each class\n",
        "         for i, class_name in enumerate(class_folders):\n",
        "            class_probability = predictions[0, i]\n",
        "            print(f\"{class_name}: {class_probability:.4f}\")\n",
        "    elif user_input.lower() == 'efficientnet':\n",
        "          efficientnet_model = create_EfficientNet_model(shape)\n",
        "          efficientnet_history = train_EfficientNet_model(efficientnet_model, train_dataset, val_dataset)\n",
        "    else :\n",
        "          print(\"Incorrect input\")\n",
        "\n",
        "          # plot_history(efficientnet_history)\n",
        "\n",
        "\n",
        "          # Assuming 'img' is an example image you want to make predictions on\n",
        "          predictions = efficientnet_model.predict(img)\n",
        "          # Display predicted probabilities for each class\n",
        "          for i, class_name in enumerate(class_folders):\n",
        "            class_probability = predictions[0, i]\n",
        "            print(f\"{class_name}: {class_probability:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaoUg5D0j3i7"
      },
      "source": [
        "# **Prediction Using saved Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtfiPMU0SY0-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/content/drive/MyDrive/Saved Model/inceptionv3_-saved-model-59-val_accuracy-0.94.hdf5')\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_path = '/content/images test.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))  # Adjust target_size based on your model's input size\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = preprocess_input(img_array)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Define class names (replace this with your actual class names)\n",
        "class_names = [\"Ajloun Castle\", \"Jeresh\", \"Petra\", \"Roman amphitheater\", \"Umm_Qais\", \"Wadi_Rum\"]\n",
        "print(\"VGGNet  Model : \")\n",
        "# Print class names and probabilities\n",
        "for class_index, (class_name, probability) in enumerate(zip(class_names, predictions[0])):\n",
        "    print(f\"{class_name}: {probability:.4f}\")\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCJYLun-Co3I"
      },
      "source": [
        "# **Gradio Interface**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr7GqO5ZOI-3"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load  saved  models\n",
        "efficientnet_model = tf.keras.models.load_model('/content/drive/MyDrive/Saved Model/efficientnet-saved-model-06-val_acc-0.98.hdf5')\n",
        "resnet_model = tf.keras.models.load_model('/content/drive/MyDrive/Saved Model/resnet50-saved-model-79-val_acc-1.00.hdf5')\n",
        "VGGNet_model = tf.keras.models.load_model('/content/drive/MyDrive/Saved Model/vgg_16_-saved-model-89-acc-0.93.hdf5')\n",
        "InceptionV3_model = tf.keras.models.load_model('/content/drive/MyDrive/Saved Model/inceptionv3_-saved-model-59-val_accuracy-0.94.hdf5')\n",
        "\n",
        "\n",
        "\n",
        "# Define class names corresponding to your dataset\n",
        "class_names = [\"Ajloun Castle\", \"Jeresh\", \"Petra\", \"Roman amphitheater\", \"Umm_Qais\", \"Wadi_Rum\"]  # Replace with your actual class names\n",
        "\n",
        "# Define the classify_image function\n",
        "def classify_image(img, model_choice):\n",
        "    # Resize the input image based on the selected model's expected input shape\n",
        "    if model_choice == \"ResNet\":\n",
        "        img = tf.image.resize(img, (150, 150))  # ResNet50 input size\n",
        "        img = image.img_to_array(img)\n",
        "        img = img.copy()  # Make a copy of the image array\n",
        "        img = resnet_preprocess_input(img)\n",
        "    elif model_choice == \"EfficientNet\":\n",
        "        img = tf.image.resize(img, (150, 150))\n",
        "        img = image.img_to_array(img)\n",
        "        img = preprocess_input(img)\n",
        "    elif model_choice == \"VGGNet\":\n",
        "        img = tf.image.resize(img, (150, 150))\n",
        "        img = image.img_to_array(img)\n",
        "        img = preprocess_input(img)\n",
        "    elif model_choice == \"InceptionV3\":\n",
        "        img = tf.image.resize(img, (150, 150))\n",
        "        img = image.img_to_array(img)\n",
        "        img = preprocess_input(img)\n",
        "    else:\n",
        "        return \"Invalid model choice\"\n",
        "\n",
        "    img = tf.expand_dims(img, 0)  # Add batch dimension\n",
        "\n",
        "    # Make predictions based on the selected model\n",
        "    if model_choice == \"ResNet\":\n",
        "        predictions = resnet_model.predict(img)\n",
        "    elif model_choice == \"EfficientNet\":\n",
        "        predictions = efficientnet_model.predict(img)\n",
        "    elif model_choice == \"VGGNet\":\n",
        "        predictions = VGGNet_model.predict(img)\n",
        "    elif model_choice == \"InceptionV3\":\n",
        "        predictions = InceptionV3_model.predict(img)\n",
        "\n",
        "    class_idx = tf.argmax(predictions[0])\n",
        "\n",
        "    # Map class index to class name\n",
        "    class_name = class_names[class_idx]\n",
        "\n",
        "    # Return the predicted class name as a string\n",
        "    return f\"Predicted class using {model_choice}: {class_name}\"\n",
        "\n",
        "# Create a Gradio interface with a dropdown for model selection\n",
        "iface = gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=[\"image\", gr.Dropdown([\"ResNet\", \"EfficientNet\",\"VGGNet\",\"InceptionV3\"], label=\"Select Model\")],\n",
        "    outputs=\"text\",\n",
        "    live=True\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch(debug=True,share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkjeUCTn8QNy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}